{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NLTK 자연어 처리 패키지"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 주요기능\r\n",
    "\r\n",
    "- 말뭉치\r\n",
    "\r\n",
    "- 토큰 생성\r\n",
    "\r\n",
    "- 형태소 분석\r\n",
    "\r\n",
    "- 품사 태깅"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 말뭉치\r\n",
    "자연어 분석 작업을 위해 만든 샘플 문서 집합.\r\n",
    "\r\n",
    "단순히 소설, 신문 등의 문서를 모아놓은 것도 있지만, \r\n",
    "\r\n",
    "품사, 형태소, 등의 보조적 의미를 추가하고 쉬운 분석을 위해 구조적인 형태로 정리해 놓은 것을 포함한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 말뭉치 자료는 설치시에 제공되지 않고 download 명령으로 사용자가 다운로드 받아야 함\r\n",
    "\r\n",
    "# 말뭉치를 다운로드\r\n",
    "import nltk\r\n",
    "nltk.download(\"book\", quiet=True)\r\n",
    "from nltk.book import *"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# ex. 저작권이 말소된 문학작품을 포함하는 gutenberg 말뭉치\r\n",
    "nltk.corpus.gutenberg.fileids() # 샘플 확인"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#  gutenberg 말뭉치 중 austen-emma 문서 확인\r\n",
    "emma_raw = nltk.corpus.gutenberg.raw(\"austen-emma.txt\")\r\n",
    "print(emma_raw[:1302])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n",
      "\n",
      "Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n",
      "less as a governess than a friend, very fond of both daughters,\n",
      "but particularly of Emma.  Between _them_ it was more the intimacy\n",
      "of sisters.  Even before Miss Taylor had ceased to hold the nominal\n",
      "office of governess, the mildness of her temper had hardly allowed\n",
      "her to impose any restraint; and the shadow of authority being\n",
      "now long passed away, they had been living together as friend and\n",
      "friend very mutually attached, and Emma doing just what she liked;\n",
      "highly esteeming Miss Taylor's judgment, but directed chiefly by\n",
      "her own.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 토큰생성\r\n",
    "자연어 문서를 분석하기 위해서는 우선 긴 문자열을 분석을 위한 작은 단위로 나누어야 한다.\r\n",
    "\r\n",
    " 이 문자열 단위를 토큰(token)이라고 하고 이렇게 문자열을 토큰으로 나누는 작업을 토큰 생성(tokenizing)이라고 한다. \r\n",
    "\r\n",
    " 영문의 경우에는 문장, 단어 등을 토큰으로 사용하거나 정규 표현식을 쓸 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 문자열을 토큰으로 분리하는 함수 :tokenizer  : 문자열을 입력받아 토큰 문자열의 리스트를 출력\r\n",
    "from nltk.tokenize import sent_tokenize\r\n",
    "print(sent_tokenize(emma_raw[:1000])[3])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n",
      "less as a governess than a friend, very fond of both daughters,\n",
      "but particularly of Emma.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from nltk.tokenize import word_tokenize\r\n",
    "word_tokenize(emma_raw[50:100])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Emma',\n",
       " 'Woodhouse',\n",
       " ',',\n",
       " 'handsome',\n",
       " ',',\n",
       " 'clever',\n",
       " ',',\n",
       " 'and',\n",
       " 'rich',\n",
       " ',',\n",
       " 'with',\n",
       " 'a']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from nltk.tokenize import RegexpTokenizer\r\n",
    "retokenize = RegexpTokenizer(\"[\\w]+\")\r\n",
    "retokenize.tokenize(emma_raw[50:100])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Emma', 'Woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 형태소 분석\r\n",
    "형태소= 언어학에서 일정한 의미가 있는 가장 작은 말의 단위를 의미.\r\n",
    "\r\n",
    "보통 자연어 처리에서는 토큰으로 형태소를 이용한다. \r\n",
    "\r\n",
    "형태소 분석(morphological analysis)이란 단어로부터 어근, 접두사, 접미사, 품사 등 다양한 언어적 속성을 파악하고 이를 이용하여 형태소를 찾아내거나 처리하는 작업이다.\r\n",
    "\r\n",
    "- 어간 추출(stemming)\r\n",
    "\r\n",
    "- 원형 복원(lemmatizing)\r\n",
    "\r\n",
    "- 품사 부착(Part-Of-Speech tagging)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - 어간 추출\r\n",
    "어간 추출은 변화된 단어의 접미사나 어미를 제거하여 같은 의미를 가지는 형태소의 기본형을 찾는 방법이다.\r\n",
    "\r\n",
    "NLTK는 PorterStemmer 와, LancasterStemmer 등을 제공한다. \r\n",
    "\r\n",
    "어간 추출법은 단순히 어미를 제거할 뿐이므로 단어의 원형의 정확히 찾아주지는 않는다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# 어간 추출\r\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer\r\n",
    "\r\n",
    "# PorterStemmer()와 LancasterStemmer() 비교\r\n",
    "st1 = PorterStemmer()\r\n",
    "st2 =  LancasterStemmer()\r\n",
    "\r\n",
    "words = [\"fly\", \"flies\", \"flying\", \"flew\", \"flown\"]\r\n",
    "\r\n",
    "print(\"Porter Stemmer   :\", [st1.stem(w) for w in words])\r\n",
    "print(\"Lancaster Stemmer:\", [st2.stem(w) for w in words])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Porter Stemmer   : ['fli', 'fli', 'fli', 'flew', 'flown']\n",
      "Lancaster Stemmer: ['fly', 'fli', 'fly', 'flew', 'flown']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - 원형복원\r\n",
    "원형 복원(lemmatizing)은 같은 의미를 가지는 여러 단어를 사전형으로 통일하는 작업이다. \r\n",
    "\r\n",
    "품사(part of speech)를 지정하는 경우 좀 더 정확한 원형을 찾을 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from nltk.stem import WordNetLemmatizer\r\n",
    "\r\n",
    "lm = WordNetLemmatizer()\r\n",
    "\r\n",
    "# words = [\"fly\", \"flies\", \"flying\", \"flew\", \"flown\"]\r\n",
    "[lm.lemmatize(w, pos=\"v\") for w in words]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['fly', 'fly', 'fly', 'fly', 'fly']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 품사부착\r\n",
    "품사(POS, part-of-speech)는 낱말을 문법적인 기능이나 형태, 뜻에 따라 구분한 것이다.\r\n",
    "\r\n",
    "NLTK에서는 펜 트리뱅크 태그세트(Penn Treebank Tagset)라는 것을 이용한다.\r\n",
    "\r\n",
    "- NNP: 단수 고유명사\r\n",
    "\r\n",
    "- VB: 동사\r\n",
    "\r\n",
    "- VBP: 동사 현재형\r\n",
    "\r\n",
    "- TO: to 전치사\r\n",
    "\r\n",
    "- NN: 명사(단수형 혹은 집합형)\r\n",
    "\r\n",
    "- DT: 관형사"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# nltk.help.upenn_tagset : 자세한 설명 확인\r\n",
    "nltk.help.upenn_tagset(\"VB\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# pos_tag : 단어 토큰에 품사를 부착하여 튜플로 출력\r\n",
    "from nltk.tag import pos_tag\r\n",
    "sentence = \"Emma refused to permit us to obtain the refuse permit\"\r\n",
    "tagged_list = pos_tag(word_tokenize(sentence))\r\n",
    "tagged_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Emma', 'NNP'),\n",
       " ('refused', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('permit', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('obtain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('refuse', 'NN'),\n",
       " ('permit', 'NN')]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 위에서 품사태그 사용해 명사NN인 토큰만 가져오기\r\n",
    "nouns_list = [t[0] for t in tagged_list if t[1] == \"NN\"]\r\n",
    "nouns_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['refuse', 'permit']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# untag: 품사태그 튜플 제거\r\n",
    "from nltk.tag import untag\r\n",
    "untag(tagged_list)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Emma',\n",
       " 'refused',\n",
       " 'to',\n",
       " 'permit',\n",
       " 'us',\n",
       " 'to',\n",
       " 'obtain',\n",
       " 'the',\n",
       " 'refuse',\n",
       " 'permit']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 같은 토큰이더라도, 품사가 다르면 다른 토큰으로 처리!\r\n",
    "-> 원래 토큰과 품사를 붙여 새로운 토큰이름을 만들어 처리해 구분하자."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def tokenizer(doc):\r\n",
    "    return [\"/\".join(p) for p in tagged_list]\r\n",
    "\r\n",
    "tokenizer(sentence)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Emma/NNP',\n",
       " 'refused/VBD',\n",
       " 'to/TO',\n",
       " 'permit/VB',\n",
       " 'us/PRP',\n",
       " 'to/TO',\n",
       " 'obtain/VB',\n",
       " 'the/DT',\n",
       " 'refuse/NN',\n",
       " 'permit/NN']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "8c1eae21719a0790335dcb83aad72b63b602cfe5cdb2bda0f60bc11d4f154e4b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}